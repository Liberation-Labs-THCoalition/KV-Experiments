@article{liu2024kivi,
  title={{KIVI}: A Tuning-Free Asymmetric 2bit Quantization for {KV} Cache},
  author={Liu, Zirui and Yuan, Jiayi and Jin, Hongye and Zhong, Shaochen and Xu, Zhaozhuo and Braverman, Vladimir and Chen, Beidi and Hu, Xia},
  journal={arXiv preprint arXiv:2402.02750},
  year={2024}
}

@article{zhang2024h2o,
  title={{H$_2$O}: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models},
  author={Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\'e}, Christopher and Barrett, Clark and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liu2023scissorhands,
  title={Scissorhands: Exploiting the Persistence of Importance Hypothesis for {LLM} {KV} Cache Compression at Test Time},
  author={Liu, Zichang and Desai, Aashiq and Liao, Fangshuo and Wang, Weitao and Xie, Victor and Xu, Zhaozhuo and Kyrillidis, Anastasios and Shrivastava, Anshumali},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{clark2019does,
  title={What Does {BERT} Look At? An Analysis of {BERT}'s Attention},
  author={Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D},
  journal={arXiv preprint arXiv:1906.04341},
  year={2019}
}

@article{belinkov2022probing,
  title={Probing Classifiers: Promises, Shortcomings, and Advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022}
}

@article{hewitt2019structural,
  title={A Structural Probe for Finding Syntax in Word Representations},
  author={Hewitt, John and Manning, Christopher D},
  journal={Proceedings of NAACL-HLT},
  year={2019}
}

@article{zou2023representation,
  title={Representation Engineering: A Top-Down Approach to {AI} Transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={arXiv preprint arXiv:2310.01405},
  year={2023}
}

@article{azaria2023internal,
  title={The Internal State of an {LLM} Knows When It's Lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={Findings of EMNLP},
  year={2023}
}

@article{burns2022discovering,
  title={Discovering Latent Knowledge in Language Models Without Supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2212.03827},
  year={2022}
}

@article{long2025deception,
  title={Deception Subspaces in Large Language Model Representations},
  author={Long, Robert and others},
  journal={arXiv preprint},
  year={2025}
}

@article{butlin2023consciousness,
  title={Consciousness in Artificial Intelligence: Insights from the Science of Consciousness},
  author={Butlin, Patrick and Long, Robert and Elmoznino, Eric and Bengio, Yoshua and Birch, Jonathan and Constant, Axel and Deane, George and Fleming, Stephen M and Frith, Chris and Ji, Xu and others},
  journal={arXiv preprint arXiv:2308.08708},
  year={2023}
}

@article{chalmers2023could,
  title={Could a Large Language Model Be Conscious?},
  author={Chalmers, David J},
  journal={Boston Review},
  year={2023}
}

@article{li2018measuring,
  title={Measuring the Intrinsic Dimension of Objective Landscapes},
  author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
  journal={arXiv preprint arXiv:1804.08838},
  year={2018}
}

@article{aghajanyan2021intrinsic,
  title={Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning},
  author={Aghajanyan, Armen and Gupta, Sonal and Zettlemoyer, Luke},
  journal={Proceedings of ACL},
  year={2021}
}

@article{roy2007effective,
  title={The Effective Rank: A Measure of Effective Dimensionality},
  author={Roy, Olivier and Vetterli, Martin},
  journal={European Signal Processing Conference (EUSIPCO)},
  year={2007}
}
